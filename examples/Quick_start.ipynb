{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf939483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "import tensorflowjs as tfjs\n",
    "import json\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63ee0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc4cfe",
   "metadata": {},
   "source": [
    "## Downloading model from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b6ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 19:24:55.914701: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 19:24:58.329019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38417 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-04-06 19:24:58.330759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38417 MB memory:  -> device: 1, name: A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2022-04-06 19:24:58.331869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 19774 MB memory:  -> device: 2, name: A100-SXM4-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "2022-04-06 19:24:58.332853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 19774 MB memory:  -> device: 3, name: A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk.\n"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/ur-whitelab/peptide-dashboard/raw/master/models/hemo-rnn/keras_model/model_weights.h5\",\n",
    "    \"model_weights.h5\",\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/ur-whitelab/peptide-dashboard/raw/master/models/hemo-rnn/keras_model/model.json\",\n",
    "    \"model.json\",\n",
    ")\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model_weights.h5\")\n",
    "print(\"Loaded model from disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1621497",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6334fe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 19:25:03.886861: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 19:25:06.025193: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "vectorized_seq = np.array([[10, 1, 18, 1, 11, 16, 1, 13, 12, 10, 11, 3, 8, 7, 14]])\n",
    "\n",
    "# function counts_aa obtains amino acid counts frequency vector\n",
    "def counts_aa(vec):\n",
    "    counts =  tf.histogram_fixed_width(vec, [0, 20], nbins=21)[1:]\n",
    "    return counts /tf.reduce_sum(counts)\n",
    "\n",
    "\n",
    "# inputs.shape[-1] needs to be 190, so we pad zeros to the end\n",
    "vectorized_seq = np.concatenate([vectorized_seq, np.zeros((vectorized_seq.shape[0], 190-vectorized_seq.shape[-1]))], axis=-1)\n",
    "vectorized_seq_fr = counts_aa(vectorized_seq)[tf.newaxis,...]\n",
    "y_predict = model.predict([vectorized_seq, vectorized_seq_fr])\n",
    "y_predict = np.array([1 if x > 0.5 else 0 for x in y_predict])\n",
    "print(y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "serverless"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
