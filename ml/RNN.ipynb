{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 16:11:42.022088: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64\n",
      "2021-10-28 16:11:42.022115: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/tmp/ipykernel_575074/3486013101.py:9: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "from dataclasses import dataclass\n",
    "import kerastuner as kt\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/whitead/dmol-book/raw/master/data/solubility.npz\",\n",
    "    \"solubility.npz\",\n",
    ")\n",
    "with np.load(\"solubility.npz\") as r:\n",
    "    pos_data, neg_data = r[\"positives\"], r[\"negatives\"]\n",
    "\n",
    "# create labels and stich it all into one\n",
    "# tensor\n",
    "labels = np.concatenate(\n",
    "    (\n",
    "        np.ones((pos_data.shape[0], 1), dtype=pos_data.dtype),\n",
    "        np.zeros((neg_data.shape[0], 1), dtype=pos_data.dtype),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "features = np.concatenate((pos_data, neg_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    vocab_size: int\n",
    "    example_number: int\n",
    "    batch_size: int\n",
    "    buffer_size: int\n",
    "    rnn_units: int\n",
    "    hidden_dim: int\n",
    "    embedding_dim: int\n",
    "    reg_strength: float\n",
    "    lr: float\n",
    "        \n",
    "config = Config(vocab_size=21, # include gap\n",
    "                example_number=len(labels), \n",
    "                batch_size=16, \n",
    "                buffer_size=10000,\n",
    "                rnn_units=16,\n",
    "                hidden_dim=32,\n",
    "                embedding_dim=8,\n",
    "                reg_strength=1e-4,\n",
    "                lr=1e-4\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we now need to shuffle before creating TF dataset\n",
    "# so that our train/test/val splits are random\n",
    "i = np.arange(len(labels))\n",
    "np.random.shuffle(i)\n",
    "labels = labels[i]\n",
    "features = features[i]\n",
    "data = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "# now split into val, test, train and batch\n",
    "N = len(data)  \n",
    "L = features[0].shape[-1]\n",
    "split = int(0.1 * N)\n",
    "test_data = data.take(split).batch(config.batch_size)\n",
    "nontest = data.skip(split)\n",
    "val_data, train_data = nontest.take(split).batch(config.batch_size), \\\n",
    "    nontest.skip(split).shuffle(config.buffer_size).batch(config.batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 200) 200\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_data.as_numpy_iterator():\n",
    "    print(x.shape, L)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(L,))\n",
    "\n",
    "# make embedding and indicate that 0 should be treated as padding mask\n",
    "e = tf.keras.layers.Embedding(input_dim=config.vocab_size, \n",
    "                                    output_dim=config.embedding_dim,\n",
    "                                    mask_zero=True)(inputs)\n",
    "\n",
    "counts = tf.keras.layers.GlobalAveragePooling1D()(e)\n",
    "\n",
    "\n",
    "# RNN layer\n",
    "x = tf.keras.layers.GRU(config.rnn_units)(e)\n",
    "x = tf.keras.layers.Concatenate()([x, counts])\n",
    "x = tf.keras.layers.LayerNormalization()(x)\n",
    "# a dense hidden layer\n",
    "x = tf.keras.layers.Dense(\n",
    "    config.hidden_dim, \n",
    "    activation='relu', \n",
    "    kernel_regularizer=tf.keras.regularizers.l2(config.reg_strength))(x)\n",
    "x = tf.keras.layers.LayerNormalization()(x)\n",
    "x = tf.keras.layers.Dense(\n",
    "    config.hidden_dim // 4, \n",
    "    activation='relu', \n",
    "    kernel_regularizer=tf.keras.regularizers.l2(config.reg_strength))(x)\n",
    "x = tf.keras.layers.LayerNormalization()(x)\n",
    "# predicting prob, so no activation\n",
    "yhat = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=yhat, name='sol-rnn')\n",
    "\n",
    "decay_steps = 1000\n",
    "lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    config.lr, decay_steps)\n",
    "\n",
    "model.compile(tf.optimizers.Adam(lr_decayed_fn),\n",
    "          loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "          metrics=[tf.keras.metrics.AUC(from_logits=True), tf.keras.metrics.BinaryAccuracy(threshold=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "923/923 [==============================] - 111s 117ms/step - loss: 0.7287 - auc_15: 0.5093 - binary_accuracy: 0.5134 - val_loss: 0.6959 - val_auc_15: 0.5427 - val_binary_accuracy: 0.5409\n",
      "Epoch 2/3\n",
      "923/923 [==============================] - 108s 117ms/step - loss: 0.7022 - auc_15: 0.5253 - binary_accuracy: 0.5288 - val_loss: 0.6959 - val_auc_15: 0.5426 - val_binary_accuracy: 0.5415\n",
      "Epoch 3/3\n",
      "923/923 [==============================] - 106s 115ms/step - loss: 0.7022 - auc_15: 0.5254 - binary_accuracy: 0.5288 - val_loss: 0.6959 - val_auc_15: 0.5426 - val_binary_accuracy: 0.5415\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(train_data, validation_data=val_data, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # make embedding and indicate that 0 should be treated as padding mask\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=config.vocab_size, \n",
    "                                        output_dim= hp.Choice('embedding_dim', [8, 16, 64]),\n",
    "                                        mask_zero=True))\n",
    "\n",
    "    # RNN layer\n",
    "    model.add(tf.keras.layers.GRU( hp.Choice('rnn_units', [32, 64, 128])))\n",
    "    # a dense hidden layer\n",
    "    hd = hp.Choice('hidden_dim', [32, 64, 128])\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'softplus'])\n",
    "    model.add(tf.keras.layers.Dense(hd, activation=activation))\n",
    "    model.add(tf.keras.layers.Dense(hd // 4, activation=activation))\n",
    "    # predicting prob, so no activation\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(tf.optimizers.Adam(hp.Choice('lr', [0.1, 1e-2, 1e-4])), \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.AUC(from_logits=True), tf.keras.metrics.BinaryAccuracy(threshold=0)])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective=kt.Objective(\"val_auc\", direction=\"max\"),\n",
    "                     max_epochs=25,\n",
    "                     factor=3,\n",
    "                     directory='/var/tmp/tuning',\n",
    "                     project_name='intro_to_kt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 Complete [00h 01m 46s]\n",
      "val_auc: 0.5\n",
      "\n",
      "Best val_auc So Far: 0.6387796998023987\n",
      "Total elapsed time: 00h 14m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "#tuner.search(train_data, epochs=50, validation_data=val_data, callbacks=[stop_early])\n",
    "#best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 32, 8, 'tanh', 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps.get('lr'), best_hps.get('rnn_units'), best_hps.get('embedding_dim'), best_hps.get('activation'), best_hps.get('hidden_dim')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
